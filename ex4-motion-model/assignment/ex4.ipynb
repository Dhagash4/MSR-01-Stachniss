{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "**_DISCLAIMER:_** The notation used in this exercise follows the one of the Probabilistic Robotics book (refer to Chapter 5.4 in case you have doubts).\n",
    "\n",
    "## 4.1 Inverse motion model\n",
    "\n",
    "The odometry model uses the _relative motion information_. The odometry readings are $u_t = [{\\overline{x}}_{t-1} , {\\overline{x}}_{t}]$, where $\\overline{x}_{t-1}$ and  $\\overline{x}_t$ are poses in a robot-internal coordinate frame (different from the map).\n",
    "\n",
    "The function `inverse_motion_model` takes as input an odometry reading $u_t$ that consist in:\n",
    "\n",
    "- the initial pose of the robot in the odometry coordinate frame $\\overline{x}_{t-1} = [\\overline{x},\\overline{y},\\overline{\\theta}]$\n",
    "- the estimated pose of the robot in the odometry coordinate frame $\\overline{x}_t = [\\overline{x}',\\overline{y}',\\overline{\\theta}']$\n",
    "\n",
    "The output is the relative motion $\\delta_{rot1}, \\delta_{trans}, \\delta_{rot2}$.\n",
    "\n",
    "Implement the function `inverse_motion_model` and verify that it is correct for some test input. **[2.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ex4\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.inv_motion_model([[0,0,0],[1,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Odometry-based motion model\n",
    "\n",
    "The function `motion_model_odometry` computes the posterior $p(x_t | u_t, x_{t-1})$ from odometry readings.\n",
    "\n",
    "This function takes as input:\n",
    "\n",
    "- the initial pose of the robot $x_{t-1} = [x,y,\\theta]$ _(**map** coordinate frame)_\n",
    "- the hypothesized (or query) final pose $x_{t} = [x', y', \\theta']$ _(**map** coordinate frame)_\n",
    "- the odometry readings $u_t = [\\overline{x}_{t-1} \\overline{x}_t]$ _(**odometry** coordinate frame)_\n",
    "- the noise parameters $\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4]$\n",
    "\n",
    "The output is the probability $p(x_t | u_t, x_{t-1})$\n",
    "\n",
    "Assume that a robot starts at pose $x_0 = [2.0, 3.0, 0.0]$ in the map frame and moves according to a motion model with $\\mathbf{\\alpha} = [1.0, 1.0, 0.01, 0.01]$.\n",
    "\n",
    "The robot excecutes one motion command and the odometry readings are:\n",
    "\n",
    "1. $\\overline{x}_0 = [0.0 , 0.0 , 0.0   ]$\n",
    "2. $\\overline{x}_1 = [0.5 , 0.0 , \\pi/2 ]$\n",
    "\n",
    "Implement the `motion_model_odometry` function and verify that it is correct for some test input. **[1.0]**\n",
    "\n",
    "---\n",
    "\n",
    "Consider a 150x150 grid map the world with a resolution of 0.01, centered in the original position of the robot.\n",
    "\n",
    "Plot the posterior $p(x_t | u_t, x_{t-1})$ for all possible $[x, y]$ values from the grid. **[2.0]**\n",
    "\n",
    "**Note that** the query input is a position, not a pose. Therefore, to plot the posterior belief over the gridmap, you can assume the term $\\hat{\\delta}_\\mathrm{rot2}$ to be zero and, for each position, integrate over all possible orientations. This can be implemented by considering $p_3 = 1.0$ in the equations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I am using triangular normal distribution we get the following plot as the result and at 1 it is at peak and hence we can verify it that motion model is correct\n",
    "\n",
    "u      = [[0.0,0.0,0.0],[1.0,0.0,0.0]]\n",
    "x_0   = [0.0,0.0,0.0]\n",
    "alph    = [1.0,1.0,0.01,0.01]\n",
    "p = []\n",
    "x = []\n",
    "for i in range(50):\n",
    "    if i<=25:\n",
    "\n",
    "        query = [1-(0.01)*i,0.0,0.0]\n",
    "        prob = ex4.motion_model_odometry(x_0,query,u,alph,gridmap = True)\n",
    "        p.append(prob)\n",
    "        x.append(query[0])\n",
    "    else:\n",
    "        query = [1+(0.01)*(i-25),0.0,0.0]\n",
    "        prob = ex4.motion_model_odometry(x_0,query,u,alph,gridmap = True)\n",
    "        p.append(prob)\n",
    "        x.append(query[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_map = np.zeros((150,150))\n",
    "u_t      = [[0.0,0.0,0.0],[0.5,0.0,math.pi/2]]\n",
    "x_init   = [2.0,3.0,0.0]\n",
    "alpha    = [1.0,1.0,0.01,0.01]\n",
    "\n",
    "for i in range(grid_map.shape[0]):\n",
    "    for j in range(grid_map.shape[1]):\n",
    "        grid_map[i][j] = ex4.motion_model_odometry(x_init,ex4.map2world(i,j,x_init,grid_map),u_t,alpha,gridmap = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4.plot_gridmap(grid_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sample odometry motion model\n",
    "\n",
    "The `motion_model_odometry` requires high computation complexity and does not scale well to large real-world environments. \n",
    "\n",
    "One effective approach to approximate $p(x_t | u_t, x_{t-1})$ is to use **sampling**.\n",
    "\n",
    "The `sample_motion_model_odometry` function defines the sampling-based odometry motion model. \n",
    "\n",
    "This function takes as input:\n",
    "\n",
    "- the initial pose of the robot $x_{t-1} = [x,y,\\theta]$ _(**map** coordinate frame)_\n",
    "- the odometry readings $u_t = [\\overline{x}_{t-1} \\overline{x}_t]$ _(**odometry** coordinate frame)_\n",
    "- the noise parameters $\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4]$\n",
    "\n",
    "The output is a new (sampled) pose predicted by the motion model.\n",
    "\n",
    "Implement the `sample_motion_model_odometry` function and verify that it is correct for some test input. **[2.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here when we sample 1000 times we get the value of x as the approximation of the distribution we are using hence we can verify that sample motion_model_odometry is correct\n",
    "\n",
    "x = np.array([0.0,0.0,0.0])\n",
    "alpha = np.array([0.1,0.1,0.01,0.01])\n",
    "u = np.array([[0.0,0.0,0.0],[1.0,0.0,0.0]])\n",
    "x_n= []\n",
    "for i in range(1000):\n",
    "    x_new,y_new,z_new = ex4.sample_motion_model(x,u,alpha)\n",
    "    x_n.append(x_new)\n",
    "x_n = np.array(x_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Evaluate sample odometry motion model\n",
    "\n",
    "Assume that a robot starts at pose $x_0 = [2.0, 3.0, 0.0]$ in the map frame and moves according to a motion model with $\\mathbf{\\alpha} = [0.1, 0.1, 0.01, 0.01]$.\n",
    "\n",
    "The robot obtains the following odometry readings:\n",
    "\n",
    "1. $\\overline{x}_0 = [0.0 , 0.0 , 0.0   ]$\n",
    "2. $\\overline{x}_1 = [0.5 , 0.0 , \\pi/2 ]$\n",
    "3. $\\overline{x}_2 = [0.5 , 0.5 , 0.0   ]$\n",
    "4. $\\overline{x}_3 = [1.0 , 0.5 , 0.0   ]$\n",
    "5. $\\overline{x}_4 = [1.0 , 1.5 , \\pi/2 ]$\n",
    "6. $\\overline{x}_5 = [1.0 , 2.5 , \\pi/2 ]$\n",
    "\n",
    "Evaluate the `sample_motion_model_odometry` by considering 1000 samples and plot the resulting positions for each sample in one unique plot. **[3.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commands = np.array([[0.0,0.0,0.0],[0.5,0.0,math.pi/2],[0.5,0.5,0.0],[1.0,0.5,0.0],[1.0,1.5,math.pi/2],[1.0,2.5,math.pi/2]])\n",
    "alpha = np.array([0.1,0.1,0.01,0.01])\n",
    "x_initials = np.array([0.0,0.0,0.0])\n",
    "n_samples = 1000\n",
    "\n",
    "samples = np.array([2.0,3.0,0.0]*1000).reshape((1000,3))\n",
    "\n",
    "for i in range(1,len(commands)):\n",
    "        \n",
    "        x_init = np.array([2.0,3.0,0.0]) + np.array(commands[i-1])\n",
    "        \n",
    "        x_initials = np.vstack((x_initials,x_init))\n",
    "        \n",
    "        count = (i-1) * 1000\n",
    "        \n",
    "        u_t = np.array([commands[i-1], commands[i]])\n",
    "      \n",
    "        for j in range(1000):\n",
    "                 \n",
    "                 x_new,y_new,theta_new = ex4.sample_motion_model(samples[count + j],u_t,alpha)\n",
    "                 pose = np.array([x_new,y_new,theta_new])\n",
    "                 samples = np.vstack((samples,pose.T))\n",
    "              \n",
    "\n",
    "x_initials = np.vstack((x_initials,[3.0,5.5,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Green line showing the true path the robot has taken if there is no noise\n",
    "\n",
    "plt.plot(x_initials[1:,0],x_initials[1:,1],\"--g\")\n",
    "\n",
    "plt.scatter(samples[:,0],samples[0:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}